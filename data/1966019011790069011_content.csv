"Content"
"	import java.io.IOException;&#xD;&#xA;	import java.util.StringTokenizer;&#xD;&#xA;	import org.apache.hadoop.conf.Configuration;&#xD;&#xA;	import org.apache.hadoop.fs.Path;&#xD;&#xA;	import org.apache.hadoop.io.IntWritable;&#xD;&#xA;	import org.apache.hadoop.io.Text;&#xD;&#xA;	import org.apache.hadoop.mapreduce.Job;&#xD;&#xA;	import org.apache.hadoop.mapreduce.Mapper;&#xD;&#xA;	import org.apache.hadoop.mapreduce.Reducer;&#xD;&#xA;	import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;&#xD;&#xA;	import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;&#xD;&#xA;	public class WordCount {&#xD;&#xA;	   public static class TokenizerMapper extends Mapper<Object, Text, Text, IntWritable>&#xD;&#xA;	   {&#xD;&#xA;		  private final static IntWritable one = new IntWritable(1);&#xD;&#xA;		  private Text word = new Text();&#xD;&#xA;		  &#xD;&#xA;		  public void map(Object key, Text value, Context context) throws IOException, InterruptedException &#xD;&#xA;		  {&#xD;&#xA;			 StringTokenizer itr = new StringTokenizer(value.toString());&#xD;&#xA;			 while (itr.hasMoreTokens()) &#xD;&#xA;			 {&#xD;&#xA;				word.set(itr.nextToken());&#xD;&#xA;				context.write(word, one);&#xD;&#xA;			 }&#xD;&#xA;		  }&#xD;&#xA;	   }&#xD;&#xA;	   &#xD;&#xA;	   public static class IntSumReducer extends Reducer<Text,IntWritable,Text,IntWritable> &#xD;&#xA;	   {&#xD;&#xA;		  private IntWritable result = new IntWritable();&#xD;&#xA;		  public void reduce(Text key, Iterable<IntWritable> values, Context context) throws IOException, InterruptedException &#xD;&#xA;		  {&#xD;&#xA;			 int sum = 0;&#xD;&#xA;			 for (IntWritable val : values) &#xD;&#xA;			 {&#xD;&#xA;				sum += val.get();&#xD;&#xA;			 }&#xD;&#xA;			 result.set(sum);&#xD;&#xA;			 context.write(key, result);&#xD;&#xA;		  }&#xD;&#xA;	   }&#xD;&#xA;	   &#xD;&#xA;	   public static void main(String[] args) throws Exception &#xD;&#xA;	   {&#xD;&#xA;		  Configuration conf = new Configuration();&#xD;&#xA;		  Job job = Job.getInstance(conf, """"word count"""");&#xD;&#xA;			&#xD;&#xA;		  job.setJarByClass(WordCount.class);&#xD;&#xA;		  job.setMapperClass(TokenizerMapper.class);&#xD;&#xA;		  job.setCombinerClass(IntSumReducer.class);&#xD;&#xA;		  job.setReducerClass(IntSumReducer.class);&#xD;&#xA;			&#xD;&#xA;		  job.setOutputKeyClass(Text.class);&#xD;&#xA;		  job.setOutputValueClass(IntWritable.class);&#xD;&#xA;			&#xD;&#xA;		  FileInputFormat.addInputPath(job, new Path(args[0]));&#xD;&#xA;		  FileOutputFormat.setOutputPath(job, new Path(args[1]));&#xD;&#xA;			&#xD;&#xA;		  System.exit(job.waitForCompletion(true) ? 0 : 1);&#xD;&#xA;	   }&#xD;&#xA;	}"
