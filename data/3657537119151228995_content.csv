"Content"
"          #!/usr/bin/env python&#xD;&#xA;          import Queue&#xD;&#xA;          import threading&#xD;&#xA;          import urllib2&#xD;&#xA;          import time&#xD;&#xA;          &#xD;&#xA;          hosts = [""""http://yahoo.com"""", """"http://google.com"""", """"http://amazon.com"""",&#xD;&#xA;          """"http://ibm.com"""", """"http://apple.com""""]&#xD;&#xA;          &#xD;&#xA;          queue = Queue.Queue()&#xD;&#xA;          &#xD;&#xA;          class ThreadUrl(threading.Thread):&#xD;&#xA;          """"""""""""Threaded Url Grab""""""""""""&#xD;&#xA;            def __init__(self, queue):&#xD;&#xA;              threading.Thread.__init__(self)&#xD;&#xA;              self.queue = queue&#xD;&#xA;          &#xD;&#xA;            def run(self):&#xD;&#xA;              while True:&#xD;&#xA;                #grabs host from queue&#xD;&#xA;                host = self.queue.get()&#xD;&#xA;            &#xD;&#xA;                #grabs urls of hosts and prints first 1024 bytes of page&#xD;&#xA;                url = urllib2.urlopen(host)&#xD;&#xA;                print url.read(1024)&#xD;&#xA;            &#xD;&#xA;                #signals to queue job is done&#xD;&#xA;                self.queue.task_done()&#xD;&#xA;          &#xD;&#xA;          start = time.time()&#xD;&#xA;          def main():&#xD;&#xA;          &#xD;&#xA;            #spawn a pool of threads, and pass them queue instance &#xD;&#xA;            for i in range(5):&#xD;&#xA;              t = ThreadUrl(queue)&#xD;&#xA;              t.setDaemon(True)&#xD;&#xA;              t.start()&#xD;&#xA;              &#xD;&#xA;           #populate queue with data   &#xD;&#xA;              for host in hosts:&#xD;&#xA;                queue.put(host)&#xD;&#xA;           &#xD;&#xA;           #wait on the queue until everything has been processed     &#xD;&#xA;           queue.join()&#xD;&#xA;          &#xD;&#xA;          main()&#xD;&#xA;          print """"Elapsed Time: %s"""" % (time.time() - start)"
